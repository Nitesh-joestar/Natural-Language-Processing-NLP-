{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2010afae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739feb51",
   "metadata": {},
   "source": [
    "d_model is the dimensions of the input and output token \n",
    "learned embeddings are the mapping of words to numeros"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7d86a6",
   "metadata": {},
   "source": [
    "## Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92478af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputEmbeddings(nn.Module):\n",
    "    def __init__(self, d_model:int,vocab:int):\n",
    "        self.d_model=d_model\n",
    "        self.vocab=vocab\n",
    "        self.embeddings=nn.Embedding(vocab,d_model)\n",
    "    def forward(self,x):\n",
    "        return self.embeddings(x)*math.sqrt(self.d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18dfb45",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self,d_model:int,seq_len:int,dropout:float):\n",
    "        super().__init__()\n",
    "        self.d_model=d_model\n",
    "        self.seq_len=seq_len\n",
    "        self.dropout=nn.Dropout(dropout)\n",
    "        pe=torch.zeros(seq_len,d_model)# [12,512]\n",
    "        position=torch.arange(0,seq_len,dtype=torch.float).unsqueeze(1) #[12] -> [12,1]\n",
    "        div_term=torch.exp(torch.arange(0,d_model,2).float()*(-math.log(10000.0)/d_model))\n",
    "        pe[:,0::2]=torch.sin(position*div_term)\n",
    "        pe[:,1::2]=torch.cos(position*div_term)\n",
    "        #pe [seq_len,d_model]\n",
    "        pe=pe.unsqueeze(0)\n",
    "        self.register_buffer('pe',pe)#buffer its saved with state dict and moves with model to position but cant be updated\n",
    "\n",
    "    def forward(self,x):\n",
    "        x=x+(self.pe[:,:x.shape[1],:]).requires_grad(False)\n",
    "        return self.dropout(x)\n",
    "    #pe[:,...,:] accesses dimensions in order first dimension get all second dimension "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a0b00d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNormalization(nn.Module):\n",
    "    def __init__(self,features:int,eps:float=10**-6)->None:\n",
    "        super().__init__()\n",
    "        self.eps=eps\n",
    "        self.alpha=nn.Parameter(torch.ones(features))\n",
    "        self.bias=nn.Parameter(torch.zeros(features))\n",
    "\n",
    "    def forward(self,x):\n",
    "        mean=x.mean(dim=-1,keepdim=True)#performs means on last dim and keep the remaining dim\n",
    "        std=x.std(dim=-1,keepdim=True)\n",
    "        return self.alpha*(x-mean)/(std+self.eps)+self.bias#eps is so that when we divide by very small number return gets very high\n",
    "    #also to prevent division by zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9fb9f28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForwardBlock(nn.Module):\n",
    "    def __init__(self,d_model:int,dff:int,dropout:float):\n",
    "        super().__init__()\n",
    "        self.linear1=nn.Linear(d_model,dff)\n",
    "        self.dropout=nn.Dropout(dropout)\n",
    "        self.linear2=nn.Linear(dff,d_model)\n",
    "\n",
    "    def forward(self,x):\n",
    "        return self.linear2(self.dropout(torch.relu(self.linear1(x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0729434",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self,h:int,dropout:float,d_model:int):\n",
    "        super().__init__()\n",
    "        self.h=h\n",
    "        self.d_model=d_model\n",
    "        assert d_model%h==0,\"D_model isnt divisible by h\"\n",
    "\n",
    "        self.d_k=d_model//h #floor division and no_ dimensions for each head\n",
    "        self.Wq=nn.Linear(d_model,d_model,bias=False)\n",
    "        self.Wk=nn.Linear(d_model,d_model,bias=False)\n",
    "        self.Wv=nn.Linear(d_model,d_model,bias=False)        \n",
    "        self.Wo=nn.Linear(d_model,d_model,bias=False)#final weight when the qkv become one and joined to form a single head\n",
    "        self.dropout=nn.Dropout(dropout)\n",
    "\n",
    "    @staticmethod\n",
    "    def attention(key,query,value,mask,dropout:nn.Dropout):\n",
    "        d_k=query.shape[-1]\n",
    "        #(batch,h,sqlen,d_k)->\n",
    "        attention_scores=(query@key.transpose(-2,-1))/math.sqrt(d_k)#formula\n",
    "        if mask is not None:\n",
    "            attention_scores.masked_fill_(mask==0,-1e9)#-ve billion so when softmax it becomes zero\n",
    "        attention_scores=attention_scores.softmax(dim=-1)\n",
    "        if dropout is not None:\n",
    "            attention_scores=dropout(attention_scores)\n",
    "        return (attention_scores@value),attention_scores\n",
    "    \n",
    "    def forward(self,q,k,v,mask):\n",
    "        query=self.Wq(q)\n",
    "        key=self.Wk(q)\n",
    "        value=self.Wv(q)\n",
    "\n",
    "        query=query.view(query.shape[0],query.shape[1],self.h,self.d_k).transpose(1,2)\n",
    "        key=key.view(key.shape[0],key.shape[1],self.h,self.d_k).transpose(1,2)\n",
    "        value=value.view(value.shape[0],value.shape[1],self.h,self.d_k).transpose(1,2)\n",
    "\n",
    "        x,self.attention_scores=MultiHeadAttention.attention(query,key,value,mask,self.dropout)\n",
    "\n",
    "        x=x.transpose(1,2).continguous().view(x.shape[0],-1,self.h*self.d_k)\n",
    "\n",
    "        return self.Wo(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b76d5482",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualConnections(nn.Module):\n",
    "    def __init__(self,features:int,dropout:float):\n",
    "        super().__init__()\n",
    "        self.dropout=nn.Dropout(dropout)\n",
    "        self.norm=LayerNormalization()\n",
    "\n",
    "    def forward(self,x,sublayer):\n",
    "        return x+self.dropout(sublayer(self.norm(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25778301",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a498c7e0",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4143acba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dropout(p=0.8, inplace=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q=nn.Dropout(0.8)\n",
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a28c67ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len=12\n",
    "d_model=512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "906a0a2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12, 512])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pe = torch.zeros(seq_len, d_model)\n",
    "pe.shape\n",
    "#12 rows and 512 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "83b24f13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "position = torch.arange(0, seq_len, dtype=torch.float)\n",
    "position.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cef58fa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12, 1])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positione = torch.arange(0, seq_len, dtype=torch.float).unsqueeze(1)\n",
    "positione.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "703b9279",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  0.,   2.,   4.,   6.,   8.,  10.,  12.,  14.,  16.,  18.,  20.,  22.,\n",
       "         24.,  26.,  28.,  30.,  32.,  34.,  36.,  38.,  40.,  42.,  44.,  46.,\n",
       "         48.,  50.,  52.,  54.,  56.,  58.,  60.,  62.,  64.,  66.,  68.,  70.,\n",
       "         72.,  74.,  76.,  78.,  80.,  82.,  84.,  86.,  88.,  90.,  92.,  94.,\n",
       "         96.,  98., 100., 102., 104., 106., 108., 110., 112., 114., 116., 118.,\n",
       "        120., 122., 124., 126., 128., 130., 132., 134., 136., 138., 140., 142.,\n",
       "        144., 146., 148., 150., 152., 154., 156., 158., 160., 162., 164., 166.,\n",
       "        168., 170., 172., 174., 176., 178., 180., 182., 184., 186., 188., 190.,\n",
       "        192., 194., 196., 198., 200., 202., 204., 206., 208., 210., 212., 214.,\n",
       "        216., 218., 220., 222., 224., 226., 228., 230., 232., 234., 236., 238.,\n",
       "        240., 242., 244., 246., 248., 250., 252., 254., 256., 258., 260., 262.,\n",
       "        264., 266., 268., 270., 272., 274., 276., 278., 280., 282., 284., 286.,\n",
       "        288., 290., 292., 294., 296., 298., 300., 302., 304., 306., 308., 310.,\n",
       "        312., 314., 316., 318., 320., 322., 324., 326., 328., 330., 332., 334.,\n",
       "        336., 338., 340., 342., 344., 346., 348., 350., 352., 354., 356., 358.,\n",
       "        360., 362., 364., 366., 368., 370., 372., 374., 376., 378., 380., 382.,\n",
       "        384., 386., 388., 390., 392., 394., 396., 398., 400., 402., 404., 406.,\n",
       "        408., 410., 412., 414., 416., 418., 420., 422., 424., 426., 428., 430.,\n",
       "        432., 434., 436., 438., 440., 442., 444., 446., 448., 450., 452., 454.,\n",
       "        456., 458., 460., 462., 464., 466., 468., 470., 472., 474., 476., 478.,\n",
       "        480., 482., 484., 486., 488., 490., 492., 494., 496., 498., 500., 502.,\n",
       "        504., 506., 508., 510.])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "div=torch.arange(0, d_model, 2).float()\n",
    "div"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
